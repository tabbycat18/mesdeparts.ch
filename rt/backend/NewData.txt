Imports from your Mac terminal (psql)

Important: don’t wrap \copy in BEGIN/COMMIT (that’s what caused the “idle-in-transaction timeout” pain).
	1.	Connect:

psql "$NEON_URL"

	2.	In psql, make it fail-fast:

\set ON_ERROR_STOP on
\timing on

	3.	Run imports (adjust filenames if yours differ):

  TRUNCATE public.xxx;

\copy public.agencies (agency_id, agency_name, agency_url, agency_timezone, agency_lang, agency_phone)
FROM '/Users/mattiapastore/Documents/VSC/MesDeparts_RT/backend/data/agency.csv'
WITH (FORMAT csv, HEADER true, QUOTE '"', ESCAPE '"', NULL '');

\copy public.stops (stop_id, stop_name, stop_lat, stop_lon, location_type, parent_station, platform_code, original_stop_id)
FROM '/Users/mattiapastore/Documents/VSC/MesDeparts_RT/backend/data/stops.csv'
WITH (FORMAT csv, HEADER true, QUOTE '"', ESCAPE '"', NULL '');

\copy public.routes (route_id, agency_id, route_short_name, route_long_name, route_desc, route_type)
FROM '/Users/mattiapastore/Documents/VSC/MesDeparts_RT/backend/data/routes.csv'
WITH (FORMAT csv, HEADER true, QUOTE '"', ESCAPE '"', NULL '');

\copy public.calendar (service_id, monday, tuesday, wednesday, thursday, friday, saturday, sunday, start_date, end_date)
FROM '/Users/mattiapastore/Documents/VSC/MesDeparts_RT/backend/data/calendar.csv'
WITH (FORMAT csv, HEADER true, QUOTE '"', ESCAPE '"', NULL '');

\copy public.calendar_dates (service_id, date, exception_type)
FROM '/Users/mattiapastore/Documents/VSC/MesDeparts_RT/backend/data/calendar_dates.csv'
WITH (FORMAT csv, HEADER true, QUOTE '"', ESCAPE '"', NULL '');

Trips import (do this safely)

Because trips.csv columns vary by feed, do this first in your Mac terminal to get the exact header:

head -n 1 /Users/mattiapastore/Documents/VSC/MesDeparts_RT/backend/data/trips.csv

Then use that exact order in the \copy (...) list.

Example (based on what you were using):

\copy public.trips (route_id, service_id, trip_id, trip_headsign, trip_short_name, direction_id, block_id, original_trip_id, hints)
FROM '/Users/mattiapastore/Documents/VSC/MesDeparts_RT/backend/data/trips.csv'
WITH (FORMAT csv, HEADER true, QUOTE '"', ESCAPE '"', NULL '');

Stop times import

\copy public.stop_times (trip_id, arrival_time, departure_time, stop_id, stop_sequence, pickup_type, drop_off_type)
FROM '/Users/mattiapastore/Documents/VSC/MesDeparts_RT/backend/data/stop_times.csv'
WITH (FORMAT csv, HEADER true, QUOTE '"', ESCAPE '"', NULL '');


⸻

Post-import “seconds fill” (the step you already did)

UPDATE public.stop_times
SET
  arrival_time_seconds = CASE
    WHEN arrival_time ~ '^[0-9]{1,3}:[0-9]{2}(:[0-9]{2})?$' THEN
      split_part(arrival_time, ':', 1)::int * 3600 +
      split_part(arrival_time, ':', 2)::int * 60 +
      COALESCE(NULLIF(split_part(arrival_time, ':', 3), '')::int, 0)
    ELSE NULL
  END,
  departure_time_seconds = CASE
    WHEN departure_time ~ '^[0-9]{1,3}:[0-9]{2}(:[0-9]{2})?$' THEN
      split_part(departure_time, ':', 1)::int * 3600 +
      split_part(departure_time, ':', 2)::int * 60 +
      COALESCE(NULLIF(split_part(departure_time, ':', 3), '')::int, 0)
    ELSE NULL
  END;

(Optional but recommended right after big imports)

ANALYZE public.stop_times;
ANALYZE public.stops;
ANALYZE public.trips;


⸻

Integrity checks (the “trip_id mismatch” detector)

SELECT 'agencies' AS t, COUNT(*) FROM public.agencies
UNION ALL SELECT 'stops', COUNT(*) FROM public.stops
UNION ALL SELECT 'routes', COUNT(*) FROM public.routes
UNION ALL SELECT 'calendar', COUNT(*) FROM public.calendar
UNION ALL SELECT 'calendar_dates', COUNT(*) FROM public.calendar_dates
UNION ALL SELECT 'trips', COUNT(*) FROM public.trips
UNION ALL SELECT 'stop_times', COUNT(*) FROM public.stop_times;

-- Stop_times referencing a trip_id that doesn’t exist in trips
SELECT COUNT(*) AS stop_times_missing_trip
FROM public.stop_times st
LEFT JOIN public.trips t ON t.trip_id = st.trip_id
WHERE t.trip_id IS NULL;

-- Trips that have no stop_times (not always an error, but useful)
SELECT COUNT(*) AS trips_missing_stop_times
FROM public.trips t
LEFT JOIN public.stop_times st ON st.trip_id = t.trip_id
WHERE st.trip_id IS NULL;


⸻

Rebuild / refresh search_stops (yes, do it)

Create once:

DROP MATERIALIZED VIEW IF EXISTS public.search_stops;

CREATE MATERIALIZED VIEW public.search_stops AS
SELECT
  s.stop_id,
  s.stop_name,
  COUNT(st.id) AS nb_stop_times,
  MIN(st.departure_time) AS first_dep,
  MAX(st.departure_time) AS last_dep
FROM public.stops s
LEFT JOIN public.stop_times st ON st.stop_id = s.stop_id
GROUP BY s.stop_id, s.stop_name;

CREATE INDEX IF NOT EXISTS idx_search_stops_name ON public.search_stops (stop_name);
CREATE INDEX IF NOT EXISTS idx_search_stops_nb   ON public.search_stops (nb_stop_times DESC);

Then whenever you reimport:

REFRESH MATERIALIZED VIEW public.search_stops;


⸻

“New timetable starts in 24h” — do you need to reimport?

[Inference] Usually it’s not a nightmare anymore: if the new GTFS feed has the same columns, you can do a TRUNCATE + reimport + seconds update + refresh search_stops.

Before doing anything, check whether your current GTFS already covers tomorrow:

SELECT
  MIN(to_date(start_date,'YYYYMMDD')) AS min_start,
  MAX(to_date(end_date,'YYYYMMDD'))   AS max_end
FROM public.calendar;

Yearly update (fast path)

If schema is unchanged, do this instead of dropping tables:

TRUNCATE public.stop_times,
         public.trips,
         public.calendar_dates,
         public.calendar,
         public.routes,
         public.stops,
         public.agencies
RESTART IDENTITY;

Then rerun the \copy imports, rerun the “seconds fill” UPDATE, and REFRESH MATERIALIZED VIEW public.search_stops;.
